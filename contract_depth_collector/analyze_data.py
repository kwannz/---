#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åˆ†æè„šæœ¬ - åˆ†ææ”¶é›†åˆ°çš„JSONæ•°æ®
"""

import json
import pandas as pd
import numpy as np
from datetime import datetime
import os
import glob
from pathlib import Path

def analyze_json_files(data_dir="data"):
    """åˆ†æJSONæ•°æ®æ–‡ä»¶"""
    print("=== å¤šäº¤æ˜“æ‰€åˆçº¦é“ºå•é‡æ•°æ®åˆ†æ ===\n")
    
    # æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
    json_files = glob.glob(os.path.join(data_dir, "depth_data_*.json"))
    if not json_files:
        print("âŒ æœªæ‰¾åˆ°JSONæ•°æ®æ–‡ä»¶")
        return
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„æ–‡ä»¶
    json_files.sort(key=os.path.getmtime, reverse=True)
    latest_file = json_files[0]
    
    print(f"ğŸ“ åˆ†ææ–‡ä»¶: {latest_file}")
    print(f"ğŸ“… æ–‡ä»¶ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(os.path.getmtime(latest_file))}")
    
    # è¯»å–JSONæ•°æ®
    with open(latest_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"ğŸ“Š æ€»è®°å½•æ•°: {len(data)}")
    print(f"ğŸ’¾ æ–‡ä»¶å¤§å°: {os.path.getsize(latest_file) / 1024:.2f} KB")
    
    # è½¬æ¢ä¸ºDataFrameè¿›è¡Œåˆ†æ
    df_data = []
    for record in data:
        df_data.append({
            'exchange': record['exchange'],
            'symbol': record['symbol'],
            'timestamp': datetime.fromtimestamp(record['timestamp']),
            'spread': record['spread'],
            'total_bid_volume': record['total_bid_volume'],
            'total_ask_volume': record['total_ask_volume'],
            'bid_count': len(record['bids']),
            'ask_count': len(record['asks']),
            'mid_price': (record['bids'][0][0] + record['asks'][0][0]) / 2 if record['bids'] and record['asks'] else 0,
            'volume_imbalance': (record['total_bid_volume'] - record['total_ask_volume']) / (record['total_bid_volume'] + record['total_ask_volume']) if (record['total_bid_volume'] + record['total_ask_volume']) > 0 else 0
        })
    
    df = pd.DataFrame(df_data)
    
    # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    print(f"\n=== åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ ===")
    print(f"æ—¶é—´èŒƒå›´: {df['timestamp'].min()} åˆ° {df['timestamp'].max()}")
    print(f"æ•°æ®æ”¶é›†æ—¶é•¿: {(df['timestamp'].max() - df['timestamp'].min()).total_seconds():.2f} ç§’")
    
    # äº¤æ˜“æ‰€åˆ†å¸ƒ
    print(f"\n=== äº¤æ˜“æ‰€åˆ†å¸ƒ ===")
    exchange_counts = df['exchange'].value_counts()
    for exchange, count in exchange_counts.items():
        print(f"{exchange}: {count} æ¡è®°å½• ({count/len(df)*100:.1f}%)")
    
    # äº¤æ˜“å¯¹åˆ†å¸ƒ
    print(f"\n=== äº¤æ˜“å¯¹åˆ†å¸ƒ ===")
    symbol_counts = df['symbol'].value_counts()
    for symbol, count in symbol_counts.items():
        print(f"{symbol}: {count} æ¡è®°å½• ({count/len(df)*100:.1f}%)")
    
    # ä»·å·®åˆ†æ
    print(f"\n=== ä»·å·®åˆ†æ ===")
    print(f"å¹³å‡ä»·å·®: {df['spread'].mean():.6f}")
    print(f"ä»·å·®ä¸­ä½æ•°: {df['spread'].median():.6f}")
    print(f"ä»·å·®æ ‡å‡†å·®: {df['spread'].std():.6f}")
    print(f"æœ€å°ä»·å·®: {df['spread'].min():.6f}")
    print(f"æœ€å¤§ä»·å·®: {df['spread'].max():.6f}")
    
    # æŒ‰äº¤æ˜“å¯¹åˆ†æä»·å·®
    print(f"\n=== å„äº¤æ˜“å¯¹ä»·å·®ç»Ÿè®¡ ===")
    for symbol in df['symbol'].unique():
        symbol_data = df[df['symbol'] == symbol]
        print(f"{symbol}:")
        print(f"  å¹³å‡ä»·å·®: {symbol_data['spread'].mean():.6f}")
        print(f"  ä»·å·®èŒƒå›´: {symbol_data['spread'].min():.6f} - {symbol_data['spread'].max():.6f}")
        print(f"  è®°å½•æ•°: {len(symbol_data)}")
    
    # æˆäº¤é‡åˆ†æ
    print(f"\n=== æˆäº¤é‡åˆ†æ ===")
    print(f"å¹³å‡ä¹°ç›˜æ€»é‡: {df['total_bid_volume'].mean():.2f}")
    print(f"å¹³å‡å–ç›˜æ€»é‡: {df['total_ask_volume'].mean():.2f}")
    print(f"æ€»ä¹°ç›˜é‡: {df['total_bid_volume'].sum():.2f}")
    print(f"æ€»å–ç›˜é‡: {df['total_ask_volume'].sum():.2f}")
    
    # è®¢å•ç°¿æ·±åº¦åˆ†æ
    print(f"\n=== è®¢å•ç°¿æ·±åº¦åˆ†æ ===")
    print(f"å¹³å‡ä¹°ç›˜æ¡£ä½æ•°: {df['bid_count'].mean():.1f}")
    print(f"å¹³å‡å–ç›˜æ¡£ä½æ•°: {df['ask_count'].mean():.1f}")
    print(f"æœ€å¤§ä¹°ç›˜æ¡£ä½: {df['bid_count'].max()}")
    print(f"æœ€å¤§å–ç›˜æ¡£ä½: {df['ask_count'].max()}")
    
    # æˆäº¤é‡ä¸å¹³è¡¡åˆ†æ
    print(f"\n=== æˆäº¤é‡ä¸å¹³è¡¡åˆ†æ ===")
    print(f"å¹³å‡ä¸å¹³è¡¡åº¦: {df['volume_imbalance'].mean():.4f}")
    print(f"ä¸å¹³è¡¡åº¦æ ‡å‡†å·®: {df['volume_imbalance'].std():.4f}")
    print(f"ä¹°ç›˜ä¼˜åŠ¿è®°å½•: {len(df[df['volume_imbalance'] > 0])} ({len(df[df['volume_imbalance'] > 0])/len(df)*100:.1f}%)")
    print(f"å–ç›˜ä¼˜åŠ¿è®°å½•: {len(df[df['volume_imbalance'] < 0])} ({len(df[df['volume_imbalance'] < 0])/len(df)*100:.1f}%)")
    
    # æ—¶é—´åºåˆ—åˆ†æ
    print(f"\n=== æ—¶é—´åºåˆ—åˆ†æ ===")
    df_sorted = df.sort_values('timestamp')
    time_intervals = df_sorted['timestamp'].diff().dropna()
    print(f"å¹³å‡æ•°æ®é—´éš”: {time_intervals.mean().total_seconds():.2f} ç§’")
    print(f"æœ€å°æ•°æ®é—´éš”: {time_intervals.min().total_seconds():.2f} ç§’")
    print(f"æœ€å¤§æ•°æ®é—´éš”: {time_intervals.max().total_seconds():.2f} ç§’")
    
    # è¯¦ç»†è®°å½•ç¤ºä¾‹
    print(f"\n=== è¯¦ç»†è®°å½•ç¤ºä¾‹ ===")
    sample_record = data[0]
    print(f"äº¤æ˜“æ‰€: {sample_record['exchange']}")
    print(f"äº¤æ˜“å¯¹: {sample_record['symbol']}")
    print(f"æ—¶é—´æˆ³: {sample_record['timestamp']}")
    print(f"æ—¶é—´: {datetime.fromtimestamp(sample_record['timestamp'])}")
    print(f"ä»·å·®: {sample_record['spread']}")
    print(f"ä¹°ç›˜æ€»é‡: {sample_record['total_bid_volume']}")
    print(f"å–ç›˜æ€»é‡: {sample_record['total_ask_volume']}")
    print(f"ä¹°ç›˜æ¡£ä½æ•°: {len(sample_record['bids'])}")
    print(f"å–ç›˜æ¡£ä½æ•°: {len(sample_record['asks'])}")
    
    print(f"\n=== ä¹°ç›˜å‰10æ¡£ ===")
    for i, bid in enumerate(sample_record['bids'][:10]):
        print(f"  {i+1:2d}. ä»·æ ¼: {bid[0]:12.6f}, æ•°é‡: {bid[1]:12.6f}")
    
    print(f"\n=== å–ç›˜å‰10æ¡£ ===")
    for i, ask in enumerate(sample_record['asks'][:10]):
        print(f"  {i+1:2d}. ä»·æ ¼: {ask[0]:12.6f}, æ•°é‡: {ask[1]:12.6f}")
    
    # ä¿å­˜åˆ†ææŠ¥å‘Š
    report_file = f"data/analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=== å¤šäº¤æ˜“æ‰€åˆçº¦é“ºå•é‡æ•°æ®åˆ†ææŠ¥å‘Š ===\n\n")
        f.write(f"åˆ†ææ—¶é—´: {datetime.now()}\n")
        f.write(f"æ•°æ®æ–‡ä»¶: {latest_file}\n")
        f.write(f"æ€»è®°å½•æ•°: {len(data)}\n")
        f.write(f"æ–‡ä»¶å¤§å°: {os.path.getsize(latest_file) / 1024:.2f} KB\n\n")
        
        f.write("=== äº¤æ˜“æ‰€åˆ†å¸ƒ ===\n")
        for exchange, count in exchange_counts.items():
            f.write(f"{exchange}: {count} æ¡è®°å½• ({count/len(df)*100:.1f}%)\n")
        
        f.write("\n=== äº¤æ˜“å¯¹åˆ†å¸ƒ ===\n")
        for symbol, count in symbol_counts.items():
            f.write(f"{symbol}: {count} æ¡è®°å½• ({count/len(df)*100:.1f}%)\n")
        
        f.write(f"\n=== ä»·å·®ç»Ÿè®¡ ===\n")
        f.write(f"å¹³å‡ä»·å·®: {df['spread'].mean():.6f}\n")
        f.write(f"ä»·å·®ä¸­ä½æ•°: {df['spread'].median():.6f}\n")
        f.write(f"ä»·å·®æ ‡å‡†å·®: {df['spread'].std():.6f}\n")
        f.write(f"æœ€å°ä»·å·®: {df['spread'].min():.6f}\n")
        f.write(f"æœ€å¤§ä»·å·®: {df['spread'].max():.6f}\n")
    
    print(f"\nâœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    return df

def main():
    """ä¸»å‡½æ•°"""
    try:
        df = analyze_json_files()
        if df is not None:
            print(f"\nğŸ‰ æ•°æ®åˆ†æå®Œæˆï¼")
            print(f"ğŸ“ˆ æˆåŠŸåˆ†æäº† {len(df)} æ¡æ·±åº¦æ•°æ®è®°å½•")
            print(f"ğŸ’¡ æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥ç”¨äºè¿›ä¸€æ­¥çš„åˆ†æå’Œå»ºæ¨¡")
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
